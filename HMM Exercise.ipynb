{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data 1 loaded: (10000, 50)\n",
      "Train data 2 loaded: (10000, 50)\n",
      "Train data 3 loaded: (10000, 50)\n",
      "Train data 4 loaded: (10000, 50)\n",
      "Train data 5 loaded: (10000, 50)\n",
      "Development data loaded: 500\n",
      "\n",
      "Starting initial probabilities:\n",
      "[0.2 0.1 0.2 0.2 0.2 0.1]\n",
      "initial[i] is the probability of starting in state i\n",
      "\n",
      "Starting transition probabilities:\n",
      "[[0.3 0.3 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.3 0.3 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.3 0.3 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.3 0.3 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.3 0.3]\n",
      " [0.3 0.1 0.1 0.1 0.1 0.3]]\n",
      "transition[i,j] is the probability of transitioning from state i to state j\n",
      "\n",
      "Starting emission probabilities\n",
      "[[0.2 0.2 0.1 0.1 0.1 0.1]\n",
      " [0.2 0.2 0.2 0.2 0.1 0.1]\n",
      " [0.2 0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2 0.2]\n",
      " [0.1 0.1 0.2 0.2 0.2 0.2]\n",
      " [0.1 0.1 0.1 0.1 0.2 0.2]]\n",
      "emission[v,i] is the probability of emitting v in state i\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 3, 3, 3, 3, 5, 5, 2, 2, 2, 2, 1, 2, 5, 5, 5, 2, 2, 2, 2,\n",
       "       2, 4, 3, 0, 3, 2, 2, 0, 4, 5, 2, 2, 2, 0, 2, 3, 3, 5, 5, 2, 2, 3,\n",
       "       3, 5, 5, 2, 2, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "\n",
    "with open(\"data/model_init.txt\") as model_init:\n",
    "    model_init.readline() # \"initial: 6\"\n",
    "    initial = np.array([float(x) for x in model_init.readline().split()])\n",
    "    model_init.readline()\n",
    "    model_init.readline() # \"transition: 6\"\n",
    "    transition = np.array([[float(x) for x in model_init.readline().split()]\n",
    "                           for _ in range(6)])\n",
    "    model_init.readline()\n",
    "    model_init.readline() # \"emission: 6\"\n",
    "    emission = np.array([[float(x) for x in model_init.readline().split()]\n",
    "                          for _ in range(6)])\n",
    "\n",
    "vocabulary = \"ABCDEF\"\n",
    "lookup = {letter: index for index, letter in enumerate(vocabulary)}\n",
    "train_data = []\n",
    "for i in range(1, 6):\n",
    "    train_data_i = []\n",
    "    with open(f\"data/seq_model_0{i}.txt\") as data:\n",
    "        for line in data:\n",
    "            train_data_i.append(np.array([lookup[letter] for letter in line.rstrip()]))\n",
    "    train_data.append(np.array(train_data_i))\n",
    "    print(f\"Train data {i} loaded: {train_data[i-1].shape}\")\n",
    "\n",
    "with open(f\"data/dev_data.txt\") as data:\n",
    "    dev_data = []\n",
    "    for line in data:\n",
    "        sequence, label = line.split(\"\\t\")\n",
    "        sequence = np.array([lookup[letter] for letter in sequence])\n",
    "        label = int(label) - 1\n",
    "        dev_data.append((sequence, label))\n",
    "print(f\"Development data loaded: {len(dev_data)}\")\n",
    "\n",
    "print()\n",
    "print(\"Starting initial probabilities:\")\n",
    "print(initial)\n",
    "print(\"initial[i] is the probability of starting in state i\")\n",
    "print()\n",
    "print(\"Starting transition probabilities:\")\n",
    "print(transition)\n",
    "print(\"transition[i,j] is the probability of transitioning from state i to state j\")\n",
    "print()\n",
    "print(\"Starting emission probabilities\")\n",
    "print(emission)\n",
    "print(\"emission[v,i] is the probability of emitting v in state i\")\n",
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, initial, transition, emission):\n",
    "        self.initial = initial.copy()\n",
    "        self.transition = transition.copy()\n",
    "        self.emission = emission.copy()\n",
    "        self.num_emissions, self.num_states = emission.shape\n",
    "    \n",
    "    def save(self, filename):\n",
    "        with open(filename, \"wb\") as out_file:\n",
    "            np.savez(out_file, initial=self.initial, transition=self.transition, emission=self.emission)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        with open(filename, \"rb\") as in_file:\n",
    "            arrays = np.load(in_file)\n",
    "            hmm = cls(arrays[\"initial\"], arrays[\"transition\"], arrays[\"emission\"])\n",
    "            arrays.close()\n",
    "        return hmm       \n",
    "    \n",
    "    def forward(self,obs):\n",
    "        a=self.transition\n",
    "        b=self.emission\n",
    "        pi=self.initial\n",
    "        nStates = np.shape(b)[0]\n",
    "        T = np.shape(obs)[0]\n",
    "\n",
    "        alpha = np.zeros((nStates,T))\n",
    "\n",
    "        alpha[:,0] = pi*b[:,obs[0]]\n",
    "\n",
    "        for t in range(1,T):\n",
    "            for s in range(nStates):\n",
    "                alpha[s,t] = b[s,obs[t]] * np.sum(alpha[:,t-1] * a[:,s])\n",
    "\n",
    "        return alpha \n",
    "    def forward_batch(self, observations):\n",
    "        nStates = np.shape(self.emission)[0]\n",
    "        batch=50\n",
    "        t=np.zeros((50,nStates,50))\n",
    "        for i in range(batch):\n",
    "            t[i,:]=self.forward(observations[i])\n",
    "        return t\n",
    "\n",
    "       \n",
    "    def backward(self,obs):\n",
    "        a=self.transition\n",
    "        b=self.emission\n",
    "        nStates = np.shape(b)[0]\n",
    "        T = np.shape(obs)[0]\n",
    "\n",
    "        beta = np.zeros((nStates,T))\n",
    "\n",
    "        beta[:,T-1] = 1.0 #aLast\n",
    "\n",
    "        for t in range(T-2,-1,-1):\n",
    "            for s in range(nStates):\n",
    "                beta[s,t] = np.sum(b[:,obs[t+1]] * beta[:,t+1] * a[s,:])\n",
    "\n",
    "        return beta \n",
    "    def backward_batch(self, observations):\n",
    "        nStates = np.shape(b)[0]\n",
    "        batch=50\n",
    "        BB=np.zeros((batch,nStates,batch))\n",
    "        for i in range(50):\n",
    "            BB[i,:]=self.backward(observations[i])\n",
    "        return BB\n",
    "    \n",
    "    def viterbi(self,obs):\n",
    "        V=obs\n",
    "        a=self.transition\n",
    "        b=self.emission\n",
    "        initial_distribution=self.initial\n",
    "        T = V.shape[0]\n",
    "        M = a.shape[0]\n",
    "\n",
    "        omega = np.zeros((T, M))\n",
    "        omega[0, :] = np.log(initial_distribution * b[:, V[0]])\n",
    "\n",
    "        prev = np.zeros((T - 1, M))\n",
    "\n",
    "        for t in range(1, T):\n",
    "            for j in range(M):\n",
    "                # Same as Forward Probability\n",
    "                probability = omega[t - 1] + np.log(a[:, j]) + np.log(b[j, V[t]])\n",
    "\n",
    "                # This is our most probable state given previous state at time t (1)\n",
    "                prev[t - 1, j] = np.argmax(probability)\n",
    "\n",
    "                # This is the probability of the most probable state (2)\n",
    "                omega[t, j] = np.max(probability)\n",
    "\n",
    "        # Path Array\n",
    "        S = np.zeros(T)\n",
    "\n",
    "        # Find the most probable last hidden state\n",
    "        last_state = np.argmax(omega[T - 1, :])\n",
    "\n",
    "        S[0] = last_state\n",
    "\n",
    "        backtrack_index = 1\n",
    "        for i in range(T - 2, -1, -1):\n",
    "            S[backtrack_index] = prev[i, int(last_state)]\n",
    "            last_state = prev[i, int(last_state)]\n",
    "            backtrack_index += 1\n",
    "\n",
    "        # Flip the path array since we were backtracking\n",
    "        S = np.flip(S, axis=0)\n",
    "        return S,omega\n",
    "    \n",
    "    \n",
    "    def baum_welch(self,obs):\n",
    "        nStates = 6\n",
    "        # Initialise pi, a, b randomly\n",
    "        pi = 1./nStates*np.ones((nStates))\n",
    "        a = np.random.rand(nStates,nStates)\n",
    "        b = np.random.rand(nStates,np.max(obs)+1)\n",
    "        nStates = np.shape(b)[0]\n",
    "        T = np.shape(obs)[0]\n",
    "        xi = np.zeros((nStates,nStates,T))\n",
    "        tol = 1e-2\n",
    "        error = tol+1\n",
    "        maxits = 50\n",
    "        nits = 0\n",
    "        pi_l=np.zeros((6,6))\n",
    "        for i in range(50):\n",
    "            while ((error > tol) & (nits < maxits)):\n",
    "                nits += 1\n",
    "                oldpi = pi.copy()\n",
    "                olda = a.copy()\n",
    "                oldb = b.copy()\n",
    "\n",
    "                # E step\n",
    "                alpha = self.forward(obs[i])\n",
    "                beta = self.backward(obs[i])\n",
    "\n",
    "                for t in range(T-1):\n",
    "                    for i in range(nStates):\n",
    "                        for j in range(nStates):\n",
    "                            xi[i,j,t] = alpha[i,t]*a[i,j]*b[j,obs[i][t+1]]*beta[j,t+1]\n",
    "                    xi[:,:,t] /= np.sum(xi[:,:,t])\n",
    "\n",
    "                # The last step has no b, beta in\n",
    "                for i in range(nStates):\n",
    "                    for j in range(nStates):\n",
    "                        xi[i,j,T-1] = alpha[i,T-1]*a[i,j]\n",
    "                xi[:,:,T-1] /= np.sum(xi[:,:,T-1])\n",
    "\n",
    "                # M step\n",
    "                for i in range(nStates):\n",
    "                    pi[i] = np.sum(xi[i,:,0])\n",
    "                    for j in range(nStates):\n",
    "                        a[i,j] = np.sum(xi[i,j,:T-1])/np.sum(xi[i,:,:T-1])\n",
    "\n",
    "                    for k in range(max(obs[0])):\n",
    "                        found = (obs==k).nonzero()\n",
    "                        b[i,k] = np.sum(xi[i,:,found])/np.sum(xi[i,:,:])\n",
    "\n",
    "                error = (np.abs(a-olda)).max() + (np.abs(b-oldb)).max()\n",
    "            \n",
    "            pi_l+=pi\n",
    "\n",
    "        return pi_l/50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567b879dd87542099707b86eac9aa775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e9d883eb5d4bdba9dc07e64538f6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71822eb52ecd4962bd16d08d2ef13809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a5f5f655ad42fe856fa888e5094e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12710a288e8b4853a2989a371302ce4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=10000), HTML(value='')), layout=Layout(displa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "hmms = [HMM(initial, transition, emission) for i in range(5)]\n",
    "batch_size = 50\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "for n,(dataset, hmm) in enumerate(zip(train_data, hmms)):\n",
    "    pbar = tqdm(total=len(dataset), ncols=\"100%\")\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        likelihood = hmm.baum_welch(dataset[i:i+batch_size])\n",
    "        pbar.set_description(f\"log-likelihood: {np.mean(np.log(likelihood)):.2f}\")\n",
    "        pbar.update(batch_size)\n",
    "    pbar.close()\n",
    "    hmm.save(os.path.join(\"models\", f\"model_{n+1}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107b9cc219464821ac93bcfa840d65aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 20.8%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "hmms = [HMM(initial, transition, emission) for i in range(5)]\n",
    "correct = 0\n",
    "pbar = tqdm(total=len(dev_data))\n",
    "for sample, label in dev_data:\n",
    "    decision = np.argmax([hmm.viterbi(sample)[1] for hmm in hmms])\n",
    "    correct += (decision == label)\n",
    "    pbar.update()\n",
    "pbar.close()\n",
    "print(f\"Accuracy: {correct / len(dev_data):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
